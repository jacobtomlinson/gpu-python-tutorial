{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ec73a2-ab2e-40df-9819-151916d9a3a0",
   "metadata": {},
   "source": [
    "# CuPy\n",
    "\n",
    "Now that we've explored some low level GPU APIs with Numba let's shift gears and work with some high level array functionality in [CuPy](https://cupy.dev/).\n",
    "\n",
    "CuPy is part of the Chainer project but has maintainers from many organisations including NVIDIA. CuPy implements the familiar Numpy API but with the backend written in CUDA C++. This allows folks who are already familiar with Numpy to get GPU acceleration out of the box quickly by just switching out an import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df9e1b-3aa3-42ea-babb-1e3576f4e2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "cp.cuda.Stream.null.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c31d8-13ae-45f0-bc52-07e5154e3456",
   "metadata": {},
   "source": [
    "Let's walk through some simple examples from this blog post https://towardsdatascience.com/heres-how-to-use-cupy-to-make-numpy-700x-faster-4b920dda1f56"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95730c-3b2c-43cd-a3c1-1f3f4744fc3d",
   "metadata": {},
   "source": [
    "## Creating arrays\n",
    "\n",
    "First let's create ourselves an `8GB` array both on the CPU and GPU and compare how long this takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d47795-4ce8-4faa-b431-15c986316872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 10\n",
    "x_cpu = np.ones((1000,500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c76949-a75c-4bd7-9062-66286e4cdc28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%timeit -n 10\n",
    "x_gpu = cp.ones((1000,500,500))\n",
    "\n",
    "cp.cuda.Stream.null.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eeed31-6939-4d43-a062-c800fb5f78fa",
   "metadata": {},
   "source": [
    "_Note we need to call `cp.cuda.Stream.null.synchronize()` explicitly here for our timings to be fair. By default cupy will run GPU code concurrently and the function will exit before the GPU has finished. Calling `synchronize()` makes us wait for the GPU to finish before returning._\n",
    "\n",
    "We can see here that creating this array on the GPU is much faster than doing so on the CPU, but this time our code looks exactly the same. We haven't had to worry about kernels, theads, blocks or any of that stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc2baf9-925f-4037-a1a5-aa74671908d6",
   "metadata": {},
   "source": [
    "## Basic operations\n",
    "\n",
    "Next let's have a look at doing some math on our arrays. We can start by multiplying every value in our arrays by `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78ba2a1-b372-4bdd-99c4-bb96a06ddc73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_cpu *= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eaae3a-8daa-4b4f-8139-b740fc589a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_gpu *= 5\n",
    "\n",
    "cp.cuda.Stream.null.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f151fee-65cf-4468-8aec-a9a41f4930fd",
   "metadata": {},
   "source": [
    "Again the GPU completes this much faster, but the code stays the same.\n",
    "\n",
    "Now let's do a couple of operations sequentially, something which would've suffered from memory transfer times in our Numba examples without explicit memory management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc2d94-96b0-40d0-830b-afdb4ab82b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_cpu *= 5\n",
    "x_cpu *= x_cpu\n",
    "x_cpu += x_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b50f5d-7595-4147-9b1e-6e388e7cf466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_gpu *= 5\n",
    "x_gpu *= x_gpu\n",
    "x_gpu += x_gpu\n",
    "\n",
    "cp.cuda.Stream.null.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4846b2fd-1f9d-4d90-bc33-38de273c9130",
   "metadata": {},
   "source": [
    "Again we can see the GPU ran that much faster even without us explicitly managing memory. This is because CuPy is handling all of this for us transparently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aabbef-7441-4ec5-8f5f-ff035b2f4879",
   "metadata": {},
   "source": [
    "## More complex operations\n",
    "\n",
    "Now that we've tried out some operators let's dive into some numpy functions. Let's compare running a singular value decomposition on a slightly smaller array of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b633495b-ae9f-477c-9df2-33e5d10cd5b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_cpu = np.random.random((1000, 1000))\n",
    "u, s, v = np.linalg.svd(x_cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69665f7-d8ba-483d-9263-edfecb45cf29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_gpu = cp.random.random((1000, 1000))\n",
    "u, s, v = cp.linalg.svd(x_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0416ed-2930-40b2-9a9a-bd53821018dc",
   "metadata": {},
   "source": [
    "As we can see the GPU outperforms the CPU again with exactly the same API.\n",
    "\n",
    "It is also interesting to note here that numpy can intelligently dispatch function calls like this. In the above example we called `cp.linalg.svd`, but we could also call `np.linalg.svd` and pass it our GPU array and numpy would inspect it and call `cp.linalg.svd` on our behalf. This makes it even easier to introduce `cupy` into your code with minimal changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34124a-d19e-4828-a161-1e605baa1317",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "x_gpu = cp.random.random((1000, 1000))\n",
    "u, s, v = np.linalg.svd(x_gpu)  # Note the `np` used here\n",
    "\n",
    "cp.cuda.Stream.null.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c68732-c354-4217-96d0-be5a53f4f5d5",
   "metadata": {},
   "source": [
    "## Devices\n",
    "\n",
    "CuPy has a concept of a current device, which is the default GPU device on which the allocation, manipulation, calculation, etc., of arrays take place. Suppose ID of the current device is `0`. In such a case, the following code would create an array `x_on_gpu0` on GPU 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b49963-75a4-41e7-ab74-662519a9f9cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with cp.cuda.Device(1):\n",
    "   x_on_gpu0 = cp.random.random((100000, 1000))\n",
    "\n",
    "x_on_gpu0.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c62867-37e4-45aa-bb15-204f471a60c5",
   "metadata": {},
   "source": [
    "In general, CuPy functions expect that the array is on the same device as the current one. Passing an array stored on a non-current device may work depending on the hardware configuration but is generally discouraged as it may not be performant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
